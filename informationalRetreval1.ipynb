{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a_xEBCm0KuNCm5SrZqU7TgILryBVTc6s",
      "authorship_tag": "ABX9TyO83yT/5cnfVWAiBqzL1AnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkShoheb33/Information-Retreval/blob/main/informationalRetreval1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GewLcHyQTdH5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upIwowsqmocw",
        "outputId": "75e55c55-9d7c-49d9-ff4d-933f67c072d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals import blocks\n",
        "class InfoRetrival:\n",
        "  def __init__(self,corpus):  \n",
        "    self.corpus = corpus\n",
        "    self.documents = []\n",
        "    self.titles = []\n",
        "    self.tokens = []\n",
        "    self.termDocs = {}\n",
        "    self.invertIndex = {}\n",
        "    self.boolIndex = {}\n",
        "    self.positionIndex = {}\n",
        "    self.biwords = {}\n",
        "    self.blocks = {}\n",
        "    for i in os.listdir(corpus):\n",
        "      self.documents.append(open(corpus+i).read())\n",
        "      self.titles.append(i[:-4])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def makeTerms(self,document):\n",
        "    terms = document.split(\" \")\n",
        "    n = len(terms)\n",
        "    for i in range(n):\n",
        "      if not terms[i].islower():\n",
        "        terms[i] = terms[i].lower()\n",
        "      terms[i] = re.sub(r'[^a-zA-Z0-9]', '', terms[i])\n",
        "    return terms\n",
        "\n",
        "\n",
        "\n",
        "  def removeStopWords(self,terms):\n",
        "    # \"i\",\"am\",\"it\",\"is\",\"the\",\"we\",\"was\",\"a\",\"an\",\"and\",\"or\",\"to\",\"so\",\n",
        "    stopWords = [\".\",\";\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"{\",\"}\",\"[\",\"]\",\":\",\"'\",\"/\",\"<\",\">\",'\"',\"+\"]\n",
        "    i = 0\n",
        "    while i < len(terms):\n",
        "      if terms[i] in stopWords  or len(terms[i])==0:\n",
        "        terms.remove(terms[i])\n",
        "      else:\n",
        "        i+=1\n",
        "    return terms\n",
        "\n",
        "\n",
        "  def stemming(self):\n",
        "    ps = PorterStemmer()\n",
        "    for title in self.termDocs:\n",
        "      n = len(self.termDocs[title])\n",
        "      for i in range(n):\n",
        "        self.termDocs[title][i] = ps.stem(self.termDocs[title][i])\n",
        "\n",
        "  def termsDocuments(self):\n",
        "    for title,docs in zip(self.titles,self.documents):\n",
        "      self.termDocs[title] = self.removeStopWords(self.makeTerms(docs))\n",
        "\n",
        "\n",
        "\n",
        "  def tokenize(self):\n",
        "    self.termsDocuments()\n",
        "    self.stemming()\n",
        "    for title in self.termDocs:\n",
        "      n = len(self.termDocs[title])\n",
        "      for i in range(n):\n",
        "        if self.termDocs[title][i] in self.tokens:\n",
        "          continue\n",
        "        self.tokens.append(self.termDocs[title][i])\n",
        "    self.tokens.sort()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def invertedIndex(self):\n",
        "    self.tokenize()\n",
        "    for token in self.tokens:\n",
        "      for doc in self.termDocs:\n",
        "        if token in self.termDocs[doc]:\n",
        "          if token not in self.invertIndex:\n",
        "            self.invertIndex[token] = []\n",
        "          self.invertIndex[token].append(doc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def booleanIndex(self):\n",
        "    self.tokenize()\n",
        "    for i in self.tokens:\n",
        "      for j in self.titles:\n",
        "        if i not in self.boolIndex:\n",
        "          self.boolIndex[i] = []\n",
        "        if j in self.invertIndex[i]:\n",
        "          self.boolIndex[i].append(1)\n",
        "        else:\n",
        "          self.boolIndex[i].append(0)\n",
        "\n",
        "\n",
        "          \n",
        "  def positionalIndex(self):\n",
        "    ps = PorterStemmer()\n",
        "    for i in self.tokens:\n",
        "      self.positionIndex[i] = {}\n",
        "      for j in self.titles:\n",
        "        document = open(self.corpus+(j+\".txt\")).read().lower().split(\" \")\n",
        "        n = len(document)\n",
        "        row = []\n",
        "        for k in range(n):\n",
        "          if i == ps.stem(document[k]):\n",
        "            row.append(k)\n",
        "        if len(row)>0:\n",
        "          self.positionIndex[i][j] = row\n",
        "\n",
        "\n",
        "\n",
        "  def biwordIndexing(self):\n",
        "    for token in self.tokens:\n",
        "      n = len(token)\n",
        "      if n>0:\n",
        "        l = ['$'+token[0]]\n",
        "        if ('$'+token[0]) not in self.biwords :\n",
        "          self.biwords['$'+token[0]] = [token]\n",
        "        else:\n",
        "          self.biwords['$'+token[0]].append(token)\n",
        "        for i in range(n-1):\n",
        "          if (token[i:i+2]) not in self.biwords :\n",
        "            self.biwords[token[i:i+2]] = [token]\n",
        "          else:\n",
        "            self.biwords[token[i:i+2]].append(token)\n",
        "        if (token[n-1]+'$') not in self.biwords :\n",
        "          self.biwords[token[n-1]+'$'] = [token]\n",
        "        else:\n",
        "          self.biwords[token[n-1]+'$'].append(token)\n",
        "\n",
        "  def wildcardQuery(self,query):\n",
        "    s = ['$'+query[0]]\n",
        "    k = 0\n",
        "    if s[-1] in [\"*$\",\"$*\"]:\n",
        "      s = ['$'+query[1]]\n",
        "      k = 1\n",
        "    for i in range(k,len(query)-1):\n",
        "      if '*' not in query[i:i+2]:\n",
        "        s.append(query[i:i+2])\n",
        "    s.append(query[-1]+'$')\n",
        "    result = set(self.biwords[s[0]])\n",
        "    for i in range(1,len(s)):\n",
        "      result = result.intersection(set(self.biwords[s[i]]))\n",
        "    return list(result)\n",
        "\n",
        "\n",
        "  def printBooleanIndex(self):\n",
        "    return pd.DataFrame(self.boolIndex,index=self.titles)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_and(self,row1,row2):\n",
        "    n = len(row1)\n",
        "    for i in range(n):\n",
        "      if row1[i] == row2[i] == 1:\n",
        "        row1[i] = 1\n",
        "      else:\n",
        "        row1[i] = 0\n",
        "    return row1\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_or(self,row1,row2):\n",
        "    n = len(row1)\n",
        "    for i in range(n):\n",
        "      if row1[i] == 1 or row2[i] == 1:\n",
        "        row1[i] = 1\n",
        "      else:\n",
        "        row1[i] = 0\n",
        "    return row1\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_not(self,row):\n",
        "    n = len(row)\n",
        "    for i in range(n):\n",
        "      if row[i] :\n",
        "        row[i] = 0\n",
        "      else:\n",
        "        row[i] = 1\n",
        "    return row\n",
        "\n",
        "\n",
        "\n",
        "  def booleanQuery(self,query):\n",
        "    query = query.split(\" \")\n",
        "    opearator = \"\"\n",
        "    flag = False\n",
        "    n = 10\n",
        "    result = []\n",
        "    for i in query:\n",
        "      if i in ['and','or']:\n",
        "        opearator = i\n",
        "      elif i == 'not':\n",
        "        flag = True\n",
        "      else:\n",
        "        if flag :\n",
        "          flag = False\n",
        "          result = self.boolean_not(self.boolIndex[i])\n",
        "        if opearator == \"and\":\n",
        "          result = self.boolean_and(result,self.boolIndex[i])\n",
        "          operator = \"\"\n",
        "        elif opearator == \"or\":\n",
        "          result = self.boolean_or(result,self.boolIndex[i])\n",
        "          operator = \"\"\n",
        "        else:\n",
        "          result = self.boolIndex[i]\n",
        "    ans = []\n",
        "    for i in range(n):\n",
        "      if result[i]:\n",
        "        ans.append(self.titles[i])\n",
        "    return ans\n",
        "  def commonDocument(self,terms):\n",
        "    commonDocs = set(self.positionIndex[terms[0]])\n",
        "    for i in range(1,len(terms)):\n",
        "      commonDocs = commonDocs.intersection(self.positionIndex[terms[i]])\n",
        "    return list(commonDocs)\n",
        "  def phraseQuery(self,query):\n",
        "    print(\"HELLo\")\n",
        "    positions = {}\n",
        "    ps = PorterStemmer()\n",
        "    query = query.lower().split(\" \")\n",
        "    n = len(query)\n",
        "    for i in range(n):\n",
        "      query[i] = ps.stem(query[i])\n",
        "    result = []\n",
        "    commonDocs = self.commonDocument(query)\n",
        "    for doc in commonDocs:\n",
        "      for position in self.positionIndex[query[0]][doc]:\n",
        "        i = 1\n",
        "        while i<n:\n",
        "          if (position+i) in self.positionIndex[query[i]][doc]:\n",
        "            i+=1\n",
        "          else:\n",
        "            break\n",
        "        if i == n:\n",
        "          result.append(doc)\n",
        "    return result\n",
        "  def correctWords(self,word):\n",
        "    result = {}\n",
        "    row = list(word)\n",
        "    for token in self.tokens:\n",
        "      dp = []\n",
        "      column = list(token)\n",
        "      for i in range(len(row)+1):\n",
        "        dp.append([0 for j in range(len(column)+1)])\n",
        "      for i in range(len(row)+1):\n",
        "        for j in range(len(column)+1):\n",
        "          if j == 0:\n",
        "            dp[i][j] = i\n",
        "          elif i == 0:\n",
        "            dp[i][j] = j\n",
        "      for i in range(1,len(row)+1):\n",
        "        for j in range(1,len(column)+1):\n",
        "          if row[i-1] == column[j-1]:\n",
        "            dp[i][j] = min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])\n",
        "          else:\n",
        "            dp[i][j] = min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])+1\n",
        "      # if dp[-1][-1] in [1,2]:\n",
        "      if dp[-1][-1] not in result:\n",
        "        result[dp[-1][-1]] = []\n",
        "      result[dp[-1][-1]].append(token)\n",
        "      # print(dp[-1][-1])\n",
        "    return result[min(result.keys())]\n",
        "\n",
        "\n",
        "  def leastFactor(self,n):\n",
        "    for i in range(2,n):\n",
        "      if n%i == 0:\n",
        "        return i\n",
        "    return 1            \n",
        "\n",
        "\n",
        "  def makeBlock(self):\n",
        "    ps = PorterStemmer()\n",
        "    n = len(os.listdir(self.corpus))\n",
        "    b = self.leastFactor(n)\n",
        "    c = 0\n",
        "    self.blocks = {}\n",
        "    c = 0\n",
        "    print(b,n)\n",
        "    for i in range(0,n,b):\n",
        "      self.blocks[\"block\"+str(c+1)] = {}\n",
        "      for j in range(i,i+b):\n",
        "        terms = self.removeStopWords(self.makeTerms(open(self.corpus+self.titles[j]+\".txt\").read()))\n",
        "        for term in terms:\n",
        "          term = ps.stem(term)\n",
        "          if term not in self.blocks[\"block\"+str(c+1)]:\n",
        "            self.blocks[\"block\"+str(c+1)][term] = []\n",
        "          if self.titles[j] not in self.blocks[\"block\"+str(c+1)][term]:\n",
        "            self.blocks[\"block\"+str(c+1)][term].append(self.titles[j])\n",
        "      c+=1\n",
        "  def mergeList(self,a,b):\n",
        "    result = []\n",
        "    n1 = len(a)\n",
        "    n2 = len(b)\n",
        "    while\n",
        "  def blockSortBasedIndexing(self):\n",
        "    n = len(self.blocks)\n",
        "    BSBI = {}\n"
      ],
      "metadata": {
        "id": "k88w8C_2UIPQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = InfoRetrival(\"/content/drive/MyDrive/stories/\")\n",
        "obj.invertedIndex()\n",
        "obj.invertIndex\n",
        "obj.booleanIndex()\n",
        "obj.boolIndex\n",
        "obj.printBooleanIndex()\n",
        "obj.booleanQuery(\"tiger or tiger\")\n",
        "# obj.positionalIndex()\n",
        "# obj.positionIndex\n",
        "# obj.phraseQuery(\"li\")\n",
        "obj.biwordIndexing()\n",
        "obj.biwords\n",
        "obj.wildcardQuery(\"e*e\")\n",
        "obj.correctWords('lon')\n",
        "obj.makeBlock()\n",
        "obj.blocks\n"
      ],
      "metadata": {
        "id": "DCjEnGpuVYuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad35a3c-dd0f-4e6d-e591-8f007b69b640"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj.blocks.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg_BRT9UKadT",
        "outputId": "286e7458-e137-490c-c7ce-1caa4e879244"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['block1', 'block2', 'block3', 'block4', 'block5'])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ]
}