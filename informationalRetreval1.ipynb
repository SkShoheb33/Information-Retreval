{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a_xEBCm0KuNCm5SrZqU7TgILryBVTc6s",
      "authorship_tag": "ABX9TyNXzLc708zSEFgwEbgzIL9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkShoheb33/Information-Retreval/blob/main/informationalRetreval1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GewLcHyQTdH5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoRetrival:\n",
        "  def __init__(self,corpus):  \n",
        "    self.corpus = corpus\n",
        "    self.documents = []\n",
        "    self.titles = []\n",
        "    self.tokens = []\n",
        "    self.termDocs = {}\n",
        "    self.invertIndex = {}\n",
        "    self.boolIndex = {}\n",
        "    self.positionIndex = {}\n",
        "    for i in os.listdir(corpus):\n",
        "      self.documents.append(open(corpus+i).read())\n",
        "      self.titles.append(i[:-4])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def makeTerms(self,document):\n",
        "    terms = document.split(\" \")\n",
        "    n = len(terms)\n",
        "    for i in range(n):\n",
        "      if not terms[i].islower():\n",
        "        terms[i] = terms[i].lower()\n",
        "      terms[i] = re.sub(r'[^a-zA-Z0-9]', '', terms[i])\n",
        "    return terms\n",
        "\n",
        "\n",
        "\n",
        "  def removeStopWords(self,terms):\n",
        "    stopWords = [\"i\",\"am\",\"it\",\"is\",\"the\",\"we\",\"was\",\"a\",\"an\",\"and\",\"or\",\"to\",\"so\",\".\",\";\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"{\",\"}\",\"[\",\"]\",\":\",\"'\",\"/\",\"<\",\">\",'\"',\"+\"]\n",
        "    i = 0\n",
        "    while i < len(terms):\n",
        "      if terms[i] in stopWords  or len(terms[i])==0:\n",
        "        terms.remove(terms[i])\n",
        "      else:\n",
        "        i+=1\n",
        "    return terms\n",
        "\n",
        "\n",
        "\n",
        "  def termsDocuments(self):\n",
        "    for title,docs in zip(self.titles,self.documents):\n",
        "      self.termDocs[title] = self.removeStopWords(self.makeTerms(docs))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def stemming(self):\n",
        "    ps = PorterStemmer()\n",
        "    for title in self.termDocs:\n",
        "      n = len(self.termDocs[title])\n",
        "      for i in range(n):\n",
        "        self.termDocs[title][i] = ps.stem(self.termDocs[title][i])\n",
        "\n",
        "\n",
        "\n",
        "  def tokenize(self):\n",
        "    self.termsDocuments()\n",
        "    self.stemming()\n",
        "    for title in self.termDocs:\n",
        "      n = len(self.termDocs[title])\n",
        "      for i in range(n):\n",
        "        if self.termDocs[title][i] in self.tokens:\n",
        "          continue\n",
        "        self.tokens.append(self.termDocs[title][i])\n",
        "    self.tokens.sort()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def invertedIndex(self):\n",
        "    self.tokenize()\n",
        "    for token in self.tokens:\n",
        "      for doc in self.termDocs:\n",
        "        if token in self.termDocs[doc]:\n",
        "          if token not in self.invertIndex:\n",
        "            self.invertIndex[token] = []\n",
        "          self.invertIndex[token].append(doc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def booleanIndex(self):\n",
        "    self.tokenize()\n",
        "    for i in self.tokens:\n",
        "      for j in self.titles:\n",
        "        if i not in self.boolIndex:\n",
        "          self.boolIndex[i] = []\n",
        "        if j in self.invertIndex[i]:\n",
        "          self.boolIndex[i].append(1)\n",
        "        else:\n",
        "          self.boolIndex[i].append(0)\n",
        "\n",
        "\n",
        "          \n",
        "  def positionalIndex(self):\n",
        "    ps = PorterStemmer()\n",
        "    for i in self.tokens:\n",
        "      self.positionIndex[i] = {}\n",
        "      for j in self.titles:\n",
        "        document = open(self.corpus+(j+\".txt\")).read().lower().split(\" \")\n",
        "        n = len(document)\n",
        "        row = []\n",
        "        for k in range(n):\n",
        "          if i == ps.stem(document[k]):\n",
        "            row.append(k)\n",
        "        if len(row)>0:\n",
        "          self.positionIndex[i][j] = row\n",
        "\n",
        "\n",
        "  def printBooleanIndex(self):\n",
        "    return pd.DataFrame(self.boolIndex,index=self.titles)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_and(self,row1,row2):\n",
        "    n = len(row1)\n",
        "    for i in range(n):\n",
        "      if row1[i] == row2[i] == 1:\n",
        "        row1[i] = 1\n",
        "      else:\n",
        "        row1[i] = 0\n",
        "    return row1\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_or(self,row1,row2):\n",
        "    n = len(row1)\n",
        "    for i in range(n):\n",
        "      if row1[i] == 1 or row2[i] == 1:\n",
        "        row1[i] = 1\n",
        "      else:\n",
        "        row1[i] = 0\n",
        "    return row1\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_not(self,row):\n",
        "    n = len(row)\n",
        "    for i in range(n):\n",
        "      if row[i] :\n",
        "        row[i] = 0\n",
        "      else:\n",
        "        row[i] = 1\n",
        "    return row\n",
        "\n",
        "\n",
        "\n",
        "  def booleanQuery(self,query):\n",
        "    query = query.split(\" \")\n",
        "    opearator = \"\"\n",
        "    flag = False\n",
        "    n = 10\n",
        "    result = []\n",
        "    for i in query:\n",
        "      if i in ['and','or']:\n",
        "        opearator = i\n",
        "      elif i == 'not':\n",
        "        flag = True\n",
        "      else:\n",
        "        if flag :\n",
        "          flag = False\n",
        "          result = self.boolean_not(self.boolIndex[i])\n",
        "        if opearator == \"and\":\n",
        "          result = self.boolean_and(result,self.boolIndex[i])\n",
        "          operator = \"\"\n",
        "        elif opearator == \"or\":\n",
        "          result = self.boolean_or(result,self.boolIndex[i])\n",
        "          operator = \"\"\n",
        "        else:\n",
        "          result = self.boolIndex[i]\n",
        "    ans = []\n",
        "    for i in range(n):\n",
        "      if result[i]:\n",
        "        ans.append(self.titles[i])\n",
        "    return ans\n",
        "\n",
        "\n",
        "\n",
        "  def phraseQuery(self,query):\n",
        "    positions = {}\n",
        "    query = query.split(\" \")\n",
        "    for word in query:\n",
        "      positions[word] = self.positionIndex[word]\n",
        "    # for "
      ],
      "metadata": {
        "id": "k88w8C_2UIPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = InfoRetrival(\"/content/drive/MyDrive/stories/\")\n",
        "obj.invertedIndex()\n",
        "obj.invertIndex\n",
        "obj.booleanIndex()\n",
        "obj.boolIndex\n",
        "obj.printBooleanIndex()\n",
        "# obj.booleanQuery(\"tiger or tiger\")\n",
        "obj.positionalIndex()\n",
        "obj.positionIndex"
      ],
      "metadata": {
        "id": "DCjEnGpuVYuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "obj.positionIndex['onc']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbIWIpiiPflT",
        "outputId": "e36c9e12-1f6d-4aa0-ffa8-2bf23a60e814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc3': [0],\n",
              " 'doc7': [0],\n",
              " 'doc8': [2, 1133, 1247],\n",
              " 'doc9': [85],\n",
              " 'doc10': [0],\n",
              " 'doc5': [2]}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj.positionIndex['upon']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAYARw8L3iWI",
        "outputId": "fc5ef694-5144-4103-8d3d-c8f38b13d172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc3': [1], 'doc7': [1], 'doc8': [3], 'doc10': [1], 'doc6': [45, 136]}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}