{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a_xEBCm0KuNCm5SrZqU7TgILryBVTc6s",
      "authorship_tag": "ABX9TyPkM8ZNFdU6U6FobDq/2Sip",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkShoheb33/Information-Retreval/blob/main/informationalRetreval1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GewLcHyQTdH5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upIwowsqmocw",
        "outputId": "e9d44a95-5dd2-4357-af84-934dce647709"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals import blocks\n",
        "class InfoRetrival:\n",
        "  def __init__(self,corpus):  \n",
        "    self.corpus = corpus\n",
        "    self.documents = []\n",
        "    self.titles = []\n",
        "    self.tokens = []\n",
        "    self.termDocs = {}\n",
        "    self.invertIndex = {}\n",
        "    self.boolIndex = {}\n",
        "    self.positionIndex = {}\n",
        "    self.biwords = {}\n",
        "    self.blocks = {}\n",
        "    self.BSBI = {}\n",
        "    self.SPIMI = {}\n",
        "    for i in os.listdir(corpus):\n",
        "      if i.split('.')[-1] == 'txt':\n",
        "        self.documents.append(open(corpus+i).read())\n",
        "        self.titles.append(i[:-4])\n",
        "        # print(self.titles[-1])\n",
        "\n",
        "  # def removeDuplicates(self,l)\n",
        "\n",
        "\n",
        "  def makeTerms(self,document):\n",
        "    terms = document.split(\" \")\n",
        "    n = len(terms)\n",
        "    for i in range(n):\n",
        "      if not terms[i].islower():\n",
        "        terms[i] = terms[i].lower()\n",
        "      terms[i] = re.sub(r'[^a-zA-Z0-9]', '', terms[i])\n",
        "    return terms\n",
        "\n",
        "\n",
        "\n",
        "  def removeStopWords(self,terms):\n",
        "    # \"i\",\"am\",\"it\",\"is\",\"the\",\"we\",\"was\",\"a\",\"an\",\"and\",\"or\",\"to\",\"so\",\n",
        "    stopWords = [\".\",\";\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"{\",\"}\",\"[\",\"]\",\":\",\"'\",\"/\",\"<\",\">\",'\"',\"+\"]\n",
        "    i = 0\n",
        "    while i < len(terms):\n",
        "      if terms[i] in stopWords  or len(terms[i])==0:\n",
        "        terms.remove(terms[i])\n",
        "      else:\n",
        "        i+=1\n",
        "    return terms\n",
        "\n",
        "\n",
        "  def stemming(self):\n",
        "    ps = PorterStemmer()\n",
        "    for title in self.termDocs:\n",
        "      n = len(self.termDocs[title])\n",
        "      for i in range(n):\n",
        "        self.termDocs[title][i] = ps.stem(self.termDocs[title][i])\n",
        "\n",
        "  def termsDocuments(self):\n",
        "    for title,docs in zip(self.titles,self.documents):\n",
        "      self.termDocs[title] = self.removeStopWords(self.makeTerms(docs))\n",
        "\n",
        "\n",
        "\n",
        "  def tokenize(self):\n",
        "    self.termsDocuments()\n",
        "    self.stemming()\n",
        "    for title in self.termDocs:\n",
        "      n = len(self.termDocs[title])\n",
        "      for i in range(n):\n",
        "        if self.termDocs[title][i] in self.tokens:\n",
        "          continue\n",
        "        self.tokens.append(self.termDocs[title][i])\n",
        "    self.tokens.sort()\n",
        "\n",
        "\n",
        "\n",
        "#1.\tBuild inverted index\n",
        "  def invertedIndex(self):\n",
        "    self.tokenize()\n",
        "    for token in self.tokens:\n",
        "      for doc in self.termDocs:\n",
        "        if token in self.termDocs[doc]:\n",
        "          if token not in self.invertIndex:\n",
        "            self.invertIndex[token] = []\n",
        "          self.invertIndex[token].append(doc)\n",
        "\n",
        "\n",
        "#2. Process Boolean queries\n",
        "  def booleanIndex(self):\n",
        "    self.tokenize()\n",
        "    for i in self.tokens:\n",
        "      for j in self.titles:\n",
        "        if i not in self.boolIndex:\n",
        "          self.boolIndex[i] = []\n",
        "        if j in self.invertIndex[i]:\n",
        "          self.boolIndex[i].append(1)\n",
        "        else:\n",
        "          self.boolIndex[i].append(0)\n",
        "\n",
        "\n",
        "  def boolean_and(self,row1,row2):\n",
        "    n = len(row1)\n",
        "    for i in range(n):\n",
        "      if row1[i] == row2[i] == 1:\n",
        "        row1[i] = 1\n",
        "      else:\n",
        "        row1[i] = 0\n",
        "    return row1\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_or(self,row1,row2):\n",
        "    n = len(row1)\n",
        "    for i in range(n):\n",
        "      if row1[i] == 1 or row2[i] == 1:\n",
        "        row1[i] = 1\n",
        "      else:\n",
        "        row1[i] = 0\n",
        "    return row1\n",
        "\n",
        "\n",
        "\n",
        "  def boolean_not(self,row):\n",
        "    n = len(row)\n",
        "    for i in range(n):\n",
        "      if row[i] :\n",
        "        row[i] = 0\n",
        "      else:\n",
        "        row[i] = 1\n",
        "    return row\n",
        "\n",
        "\n",
        "\n",
        "  def booleanQuery(self,query):\n",
        "    query = query.split(\" \")\n",
        "    opearator = \"\"\n",
        "    flag = False\n",
        "    n = 10\n",
        "    result = []\n",
        "    for i in query:\n",
        "      if i in ['and','or']:\n",
        "        opearator = i\n",
        "      elif i == 'not':\n",
        "        flag = True\n",
        "      else:\n",
        "        if flag :\n",
        "          flag = False\n",
        "          result = self.boolean_not(self.boolIndex[i])\n",
        "        if opearator == \"and\":\n",
        "          result = self.boolean_and(result,self.boolIndex[i])\n",
        "          operator = \"\"\n",
        "        elif opearator == \"or\":\n",
        "          result = self.boolean_or(result,self.boolIndex[i])\n",
        "          operator = \"\"\n",
        "        else:\n",
        "          result = self.boolIndex[i]\n",
        "    ans = []\n",
        "    for i in range(n):\n",
        "      if result[i]:\n",
        "        ans.append(self.titles[i])\n",
        "    return ans\n",
        "\n",
        "  #3.\tBuild positional index and process phrase queries\n",
        "  def positionalIndex(self):\n",
        "    ps = PorterStemmer()\n",
        "    for i in self.tokens:\n",
        "      self.positionIndex[i] = {}\n",
        "      for j in self.titles:\n",
        "        document = open(self.corpus+(j+\".txt\")).read().lower().split(\" \")\n",
        "        n = len(document)\n",
        "        row = []\n",
        "        for k in range(n):\n",
        "          if i == ps.stem(document[k]):\n",
        "            row.append(k)\n",
        "        if len(row)>0:\n",
        "          self.positionIndex[i][j] = row\n",
        "\n",
        "  def commonDocument(self,terms):\n",
        "    commonDocs = set(self.positionIndex[terms[0]])\n",
        "    for i in range(1,len(terms)):\n",
        "      commonDocs = commonDocs.intersection(self.positionIndex[terms[i]])\n",
        "    return list(commonDocs)\n",
        "\n",
        "\n",
        "  def phraseQuery(self,query):\n",
        "    print(\"HELLo\")\n",
        "    positions = {}\n",
        "    ps = PorterStemmer()\n",
        "    query = query.lower().split(\" \")\n",
        "    n = len(query)\n",
        "    for i in range(n):\n",
        "      query[i] = ps.stem(query[i])\n",
        "    result = []\n",
        "    commonDocs = self.commonDocument(query)\n",
        "    for doc in commonDocs:\n",
        "      for position in self.positionIndex[query[0]][doc]:\n",
        "        i = 1\n",
        "        while i<n:\n",
        "          if (position+i) in self.positionIndex[query[i]][doc]:\n",
        "            i+=1\n",
        "          else:\n",
        "            break\n",
        "        if i == n:\n",
        "          result.append(doc)\n",
        "    return result\n",
        "\n",
        "\n",
        "#4.\tBuild bi-gram index and process wildcard queries\n",
        "  def biwordIndexing(self):\n",
        "    for token in self.tokens:\n",
        "      n = len(token)\n",
        "      if n>0:\n",
        "        l = ['$'+token[0]]\n",
        "        if ('$'+token[0]) not in self.biwords :\n",
        "          self.biwords['$'+token[0]] = [token]\n",
        "        else:\n",
        "          self.biwords['$'+token[0]].append(token)\n",
        "        for i in range(n-1):\n",
        "          if (token[i:i+2]) not in self.biwords :\n",
        "            self.biwords[token[i:i+2]] = [token]\n",
        "          else:\n",
        "            self.biwords[token[i:i+2]].append(token)\n",
        "        if (token[n-1]+'$') not in self.biwords :\n",
        "          self.biwords[token[n-1]+'$'] = [token]\n",
        "        else:\n",
        "          self.biwords[token[n-1]+'$'].append(token)\n",
        "\n",
        "  def wildcardQuery(self,query):\n",
        "    s = ['$'+query[0]]\n",
        "    k = 0\n",
        "    if s[-1] in [\"*$\",\"$*\"]:\n",
        "      s = ['$'+query[1]]\n",
        "      k = 1\n",
        "    for i in range(k,len(query)-1):\n",
        "      if '*' not in query[i:i+2]:\n",
        "        s.append(query[i:i+2])\n",
        "    s.append(query[-1]+'$')\n",
        "    result = set(self.biwords[s[0]])\n",
        "    for i in range(1,len(s)):\n",
        "      result = result.intersection(set(self.biwords[s[i]]))\n",
        "    return list(result)\n",
        "\n",
        "\n",
        "  def printBooleanIndex(self):\n",
        "    return pd.DataFrame(self.boolIndex,index=self.titles)\n",
        "\n",
        "\n",
        "#5.\tCorrect spellings in the query using edit distance\n",
        "  def correctWords(self,word):\n",
        "    result = {}\n",
        "    row = list(word)\n",
        "    for token in self.tokens:\n",
        "      dp = []\n",
        "      column = list(token)\n",
        "      for i in range(len(row)+1):\n",
        "        dp.append([0 for j in range(len(column)+1)])\n",
        "      for i in range(len(row)+1):\n",
        "        for j in range(len(column)+1):\n",
        "          if j == 0:\n",
        "            dp[i][j] = i\n",
        "          elif i == 0:\n",
        "            dp[i][j] = j\n",
        "      for i in range(1,len(row)+1):\n",
        "        for j in range(1,len(column)+1):\n",
        "          if row[i-1] == column[j-1]:\n",
        "            dp[i][j] = min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])\n",
        "          else:\n",
        "            dp[i][j] = min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])+1\n",
        "      # if dp[-1][-1] in [1,2]:\n",
        "      if dp[-1][-1] not in result:\n",
        "        result[dp[-1][-1]] = []\n",
        "      result[dp[-1][-1]].append(token)\n",
        "      # print(dp[-1][-1])\n",
        "    return result[min(result.keys())]\n",
        "\n",
        "\n",
        "  def leastFactor(self,n):\n",
        "    for i in range(2,n):\n",
        "      if n%i == 0:\n",
        "        return i\n",
        "    return 1            \n",
        "\n",
        "#6.\tImplement BSBI algorithm\n",
        "  def makeBlock(self):\n",
        "    ps = PorterStemmer()\n",
        "    n = len(self.titles)\n",
        "    b = self.leastFactor(n)\n",
        "    c = 0\n",
        "    self.blocks = {}\n",
        "    c = 0\n",
        "    # print(b,n)\n",
        "    for i in range(0,n,b):\n",
        "      self.blocks[\"block\"+str(c+1)] = {}\n",
        "      for j in range(i,i+b):\n",
        "        terms = self.removeStopWords(self.makeTerms(open(self.corpus+self.titles[j]+\".txt\").read()))\n",
        "        for term in terms:\n",
        "          term = ps.stem(term)\n",
        "          if term not in self.blocks[\"block\"+str(c+1)]:\n",
        "            self.blocks[\"block\"+str(c+1)][term] = []\n",
        "          if self.titles[j] not in self.blocks[\"block\"+str(c+1)][term]:\n",
        "            self.blocks[\"block\"+str(c+1)][term].append(self.titles[j])\n",
        "      c+=1\n",
        "\n",
        "\n",
        "\n",
        "  def mergeDocs(self,doc1,doc2):\n",
        "    doc1.sort()\n",
        "    doc2.sort()\n",
        "    m = len(doc1)\n",
        "    n = len(doc2)\n",
        "    result = []\n",
        "    i,j = 0,0\n",
        "    while i<m and j<n:\n",
        "      if doc1[i] == doc2[j]:\n",
        "        result.append(doc1[i])\n",
        "        i+=1\n",
        "        j+=1\n",
        "      elif doc1[i] < doc2[j]:\n",
        "        result.append(doc1[i])\n",
        "        i+=1\n",
        "      else:\n",
        "        result.append(doc2[j])\n",
        "        j+=1\n",
        "    while i < m:\n",
        "      result.append(doc1[i])\n",
        "      i+=1\n",
        "    while j < n:\n",
        "      result.append(doc2[j])\n",
        "      j+=1\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "  def mergeBlocks(self,blockA,blockB):\n",
        "    termsA = list(blockA.keys())\n",
        "    termsB = list(blockB.keys())\n",
        "    termsA.sort()\n",
        "    termsB.sort()\n",
        "    m = len(termsA)\n",
        "    n = len(termsB)\n",
        "    result = {}\n",
        "    i,j = 0,0\n",
        "    while i < m  and j <n :\n",
        "      if termsA[i] == termsB[j]:\n",
        "        result[termsA[i]] = self.mergeDocs(blockA[termsA[i]],blockB[termsB[j]])\n",
        "        i+=1\n",
        "        j+=1\n",
        "      elif termsA[i] < termsB[j]:\n",
        "        result[termsA[i]] =blockA[termsA[i]]\n",
        "        i+=1\n",
        "      else:\n",
        "        result[termsB[j]] = blockB[termsB[j]]\n",
        "        j+=1\n",
        "    while  i < m:\n",
        "      result[termsA[i]] = blockA[termsA[i]]\n",
        "      i+=1\n",
        "    while  j < n:\n",
        "      result[termsB[j]] = blockB[termsB[j]]\n",
        "      j+=1\n",
        "    return result\n",
        "\n",
        "\n",
        "  def blockSortBasedIndexing(self):\n",
        "    n = len(self.blocks)\n",
        "    self.BSBI = self.mergeBlocks(self.blocks['block1'],{})\n",
        "    for i in range(2,n+1):\n",
        "      self.BSBI = self.mergeBlocks(self.BSBI,self.blocks[f'block{i}'])\n",
        "\n",
        "#7.\tImplement SPIMI algorithm\n",
        "  def singlePassInMemoryIndexing(self,corpus):\n",
        "    path = self.corpus+'/dictionary.json'\n",
        "    # if os.path.exists(path):\n",
        "    #   with open(path,'r') as f:\n",
        "    #     self.SPIMI = json.load(f)\n",
        "    for title in self.titles:\n",
        "      if len(self.SPIMI)==0:\n",
        "        for word in sorted(list(set(self.termDocs[title]))):\n",
        "          self.SPIMI[word] = [title]\n",
        "      else:\n",
        "        for word in sorted(list(set(self.termDocs[title]))):\n",
        "          if word in self.SPIMI:\n",
        "            self.SPIMI[word].append(title)\n",
        "          else:\n",
        "            self.SPIMI[word] = [title]\n",
        "    # with open(path,'w') as f:\n",
        "    #   json.dump(self.SPIMI,f)\n",
        "    # return self.SPIMI\n",
        "\n",
        "      \n",
        "      \n"
      ],
      "metadata": {
        "id": "k88w8C_2UIPQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = InfoRetrival(\"/content/drive/MyDrive/stories/\")\n",
        "obj.invertedIndex()\n",
        "obj.invertIndex\n",
        "obj.booleanIndex()\n",
        "obj.boolIndex\n",
        "obj.printBooleanIndex()\n",
        "obj.booleanQuery(\"tiger or tiger\")\n",
        "# obj.positionalIndex()\n",
        "# obj.positionIndex\n",
        "# obj.phraseQuery(\"li\")\n",
        "obj.biwordIndexing()\n",
        "obj.biwords\n",
        "obj.wildcardQuery(\"e*e\")\n",
        "obj.correctWords('lon')\n",
        "obj.makeBlock()\n",
        "obj.blocks\n",
        "obj.blockSortBasedIndexing()\n",
        "obj.BSBI\n",
        "obj.singlePassInMemoryIndexing(\"/content/drive/MyDrive/stories\")"
      ],
      "metadata": {
        "id": "DCjEnGpuVYuu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obj.printBooleanIndex()"
      ],
      "metadata": {
        "id": "qg_BRT9UKadT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/stories')\n",
        "# sorted(obj.termDocs['doc1'])\n",
        "obj.SPIMI"
      ],
      "metadata": {
        "id": "pnX0z7rmieer",
        "outputId": "ad571443-a98c-4700-f0b6-a1bce44e7dc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': ['doc1',\n",
              "  'doc2',\n",
              "  'doc3',\n",
              "  'doc4',\n",
              "  'doc7',\n",
              "  'doc8',\n",
              "  'doc9',\n",
              "  'doc10',\n",
              "  'doc5',\n",
              "  'doc6'],\n",
              " 'act': ['doc1', 'doc3'],\n",
              " 'after': ['doc1', 'doc3', 'doc4', 'doc8'],\n",
              " 'agre': ['doc1', 'doc10'],\n",
              " 'amus': ['doc1'],\n",
              " 'and': ['doc1',\n",
              "  'doc2',\n",
              "  'doc3',\n",
              "  'doc4',\n",
              "  'doc7',\n",
              "  'doc8',\n",
              "  'doc9',\n",
              "  'doc10',\n",
              "  'doc5',\n",
              "  'doc6'],\n",
              " 'anywher': ['doc1'],\n",
              " 'as': ['doc1', 'doc2', 'doc3', 'doc8', 'doc9', 'doc10', 'doc5'],\n",
              " 'ask': ['doc1', 'doc3', 'doc10'],\n",
              " 'at': ['doc1', 'doc4', 'doc8', 'doc9', 'doc10'],\n",
              " 'be': ['doc1', 'doc8', 'doc10'],\n",
              " 'besid': ['doc1'],\n",
              " 'but': ['doc1', 'doc3', 'doc4', 'doc7', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'catch': ['doc1'],\n",
              " 'consent': ['doc1'],\n",
              " 'could': ['doc1', 'doc3', 'doc4', 'doc8', 'doc10', 'doc6'],\n",
              " 'cours': ['doc1', 'doc2', 'doc8'],\n",
              " 'day': ['doc1', 'doc3', 'doc4', 'doc7', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'deepli': ['doc1'],\n",
              " 'did': ['doc1', 'doc8', 'doc10'],\n",
              " 'distanc': ['doc1', 'doc9'],\n",
              " 'down': ['doc1', 'doc8', 'doc9'],\n",
              " 'ever': ['doc1', 'doc8', 'doc10'],\n",
              " 'far': ['doc1', 'doc8'],\n",
              " 'feel': ['doc1'],\n",
              " 'for': ['doc1', 'doc2', 'doc3', 'doc4', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'fox': ['doc1', 'doc3', 'doc9'],\n",
              " 'fun': ['doc1'],\n",
              " 'get': ['doc1', 'doc8', 'doc9'],\n",
              " 'go': ['doc1', 'doc8', 'doc10'],\n",
              " 'goal': ['doc1'],\n",
              " 'had': ['doc1', 'doc3', 'doc8', 'doc9', 'doc5', 'doc6'],\n",
              " 'hare': ['doc1'],\n",
              " 'he': ['doc1', 'doc3', 'doc4', 'doc7', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'hi': ['doc1', 'doc7', 'doc8', 'doc10', 'doc6'],\n",
              " 'him': ['doc1', 'doc3', 'doc7', 'doc8', 'doc10'],\n",
              " 'how': ['doc1', 'doc3', 'doc8'],\n",
              " 'i': ['doc1', 'doc3', 'doc8', 'doc9', 'doc10', 'doc5'],\n",
              " 'idea': ['doc1', 'doc4'],\n",
              " 'ill': ['doc1', 'doc8'],\n",
              " 'in': ['doc1',\n",
              "  'doc2',\n",
              "  'doc3',\n",
              "  'doc4',\n",
              "  'doc7',\n",
              "  'doc8',\n",
              "  'doc9',\n",
              "  'doc10',\n",
              "  'doc6'],\n",
              " 'it': ['doc1', 'doc2', 'doc3', 'doc4', 'doc8', 'doc9', 'doc10', 'doc5'],\n",
              " 'itth': ['doc1', 'doc3', 'doc4'],\n",
              " 'judg': ['doc1'],\n",
              " 'kept': ['doc1'],\n",
              " 'last': ['doc1', 'doc8'],\n",
              " 'laughy': ['doc1'],\n",
              " 'lay': ['doc1', 'doc8'],\n",
              " 'make': ['doc1', 'doc3', 'doc8', 'doc6'],\n",
              " 'mark': ['doc1'],\n",
              " 'meanwhil': ['doc1'],\n",
              " 'mock': ['doc1'],\n",
              " 'much': ['doc1', 'doc8'],\n",
              " 'nap': ['doc1'],\n",
              " 'near': ['doc1', 'doc8'],\n",
              " 'not': ['doc1', 'doc3', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'now': ['doc1', 'doc3', 'doc8', 'doc10'],\n",
              " 'of': ['doc1',\n",
              "  'doc2',\n",
              "  'doc3',\n",
              "  'doc4',\n",
              "  'doc7',\n",
              "  'doc8',\n",
              "  'doc9',\n",
              "  'doc10',\n",
              "  'doc5',\n",
              "  'doc6'],\n",
              " 'offth': ['doc1'],\n",
              " 'on': ['doc1', 'doc2', 'doc3', 'doc8', 'doc10', 'doc5'],\n",
              " 'one': ['doc1', 'doc2', 'doc4', 'doc8', 'doc9', 'doc10', 'doc5', 'doc6'],\n",
              " 'out': ['doc1', 'doc3', 'doc7', 'doc8', 'doc9', 'doc10'],\n",
              " 'overtak': ['doc1'],\n",
              " 'pass': ['doc1', 'doc8'],\n",
              " 'peac': ['doc1'],\n",
              " 'place': ['doc1', 'doc3'],\n",
              " 'prove': ['doc1'],\n",
              " 'race': ['doc1'],\n",
              " 'ran': ['doc1', 'doc7', 'doc8', 'doc10'],\n",
              " 'repli': ['doc1', 'doc3'],\n",
              " 'ridicul': ['doc1'],\n",
              " 'run': ['doc1', 'doc3', 'doc8', 'doc9', 'doc10'],\n",
              " 'runner': ['doc1'],\n",
              " 'should': ['doc1'],\n",
              " 'sight': ['doc1'],\n",
              " 'sleep': ['doc1'],\n",
              " 'slept': ['doc1'],\n",
              " 'slowdo': ['doc1'],\n",
              " 'slowli': ['doc1', 'doc8', 'doc10'],\n",
              " 'so': ['doc1', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'soon': ['doc1', 'doc3', 'doc8', 'doc10'],\n",
              " 'sooner': ['doc1'],\n",
              " 'start': ['doc1', 'doc8', 'doc10'],\n",
              " 'steadili': ['doc1'],\n",
              " 'swiftest': ['doc1'],\n",
              " 'take': ['doc1', 'doc3', 'doc8', 'doc10'],\n",
              " 'than': ['doc1', 'doc8'],\n",
              " 'the': ['doc1',\n",
              "  'doc2',\n",
              "  'doc3',\n",
              "  'doc4',\n",
              "  'doc7',\n",
              "  'doc8',\n",
              "  'doc9',\n",
              "  'doc10',\n",
              "  'doc5',\n",
              "  'doc6'],\n",
              " 'there': ['doc1', 'doc3', 'doc4', 'doc7', 'doc8', 'doc10', 'doc5', 'doc6'],\n",
              " 'thing': ['doc1'],\n",
              " 'think': ['doc1', 'doc8'],\n",
              " 'time': ['doc1', 'doc2', 'doc3', 'doc7', 'doc8', 'doc9', 'doc10', 'doc6'],\n",
              " 'to': ['doc1',\n",
              "  'doc2',\n",
              "  'doc3',\n",
              "  'doc4',\n",
              "  'doc7',\n",
              "  'doc8',\n",
              "  'doc9',\n",
              "  'doc10',\n",
              "  'doc5',\n",
              "  'doc6'],\n",
              " 'tortois': ['doc1'],\n",
              " 'tri': ['doc1', 'doc8', 'doc9'],\n",
              " 'until': ['doc1', 'doc4', 'doc8'],\n",
              " 'up': ['doc1', 'doc4', 'doc8', 'doc10'],\n",
              " 'upth': ['doc1'],\n",
              " 'veri': ['doc1', 'doc3', 'doc8', 'doc9', 'doc10'],\n",
              " 'wa': ['doc1', 'doc3', 'doc4', 'doc7', 'doc8', 'doc10', 'doc5'],\n",
              " 'wake': ['doc1'],\n",
              " 'when': ['doc1', 'doc3', 'doc4', 'doc8', 'doc10', 'doc5', 'doc6'],\n",
              " 'where': ['doc1', 'doc8'],\n",
              " 'who': ['doc1', 'doc8', 'doc10', 'doc5'],\n",
              " 'with': ['doc1', 'doc3', 'doc4', 'doc8', 'doc9', 'doc10', 'doc5'],\n",
              " 'you': ['doc1', 'doc2', 'doc3', 'doc8', 'doc10'],\n",
              " 'about': ['doc2', 'doc8', 'doc10', 'doc6'],\n",
              " 'action': ['doc2'],\n",
              " 'all': ['doc2', 'doc8', 'doc10', 'doc6'],\n",
              " 'an': ['doc2', 'doc8', 'doc10', 'doc6'],\n",
              " 'anim': ['doc2', 'doc3', 'doc10'],\n",
              " 'animaly': ['doc2'],\n",
              " 'attribut': ['doc2'],\n",
              " 'behaviour': ['doc2'],\n",
              " 'below': ['doc2'],\n",
              " 'best': ['doc2', 'doc6'],\n",
              " 'bring': ['doc2', 'doc8'],\n",
              " 'can': ['doc2', 'doc8'],\n",
              " 'characterist': ['doc2'],\n",
              " 'children': ['doc2', 'doc5'],\n",
              " 'click': ['doc2'],\n",
              " 'convey': ['doc2'],\n",
              " 'cornerston': ['doc2'],\n",
              " 'do': ['doc2', 'doc8'],\n",
              " 'download': ['doc2'],\n",
              " 'due': ['doc2', 'doc10', 'doc6'],\n",
              " 'educ': ['doc2'],\n",
              " 'entir': ['doc2'],\n",
              " 'exhibit': ['doc2'],\n",
              " 'explain': ['doc2'],\n",
              " 'fabl': ['doc2'],\n",
              " 'format': ['doc2'],\n",
              " 'free': ['doc2'],\n",
              " 'help': ['doc2', 'doc7'],\n",
              " 'here': ['doc2', 'doc8', 'doc9'],\n",
              " 'histori': ['doc2'],\n",
              " 'human': ['doc2'],\n",
              " 'illustr': ['doc2'],\n",
              " 'impart': ['doc2'],\n",
              " 'inspir': ['doc2'],\n",
              " 'interest': ['doc2'],\n",
              " 'irrespect': ['doc2'],\n",
              " 'is': ['doc2', 'doc3', 'doc8', 'doc10'],\n",
              " 'kid': ['doc2'],\n",
              " 'kind': ['doc2', 'doc8'],\n",
              " 'know': ['doc2', 'doc8', 'doc6'],\n",
              " 'lesson': ['doc2'],\n",
              " 'like': ['doc2', 'doc3', 'doc8'],\n",
              " 'link': ['doc2'],\n",
              " 'lion': ['doc2', 'doc7', 'doc10', 'doc6'],\n",
              " 'littl': ['doc2', 'doc4', 'doc8', 'doc10'],\n",
              " 'merci': ['doc2'],\n",
              " 'messag': ['doc2'],\n",
              " 'moral': ['doc2'],\n",
              " 'mous': ['doc2', 'doc8'],\n",
              " 'need': ['doc2', 'doc10'],\n",
              " 'other': ['doc2', 'doc3', 'doc10', 'doc6'],\n",
              " 'pdf': ['doc2'],\n",
              " 'principl': ['doc2'],\n",
              " 'provid': ['doc2'],\n",
              " 'read': ['doc2'],\n",
              " 'reap': ['doc2'],\n",
              " 'render': ['doc2'],\n",
              " 'reward': ['doc2'],\n",
              " 'serv': ['doc2', 'doc3'],\n",
              " 'short': ['doc2', 'doc9'],\n",
              " 'size': ['doc2'],\n",
              " 'stori': ['doc2'],\n",
              " 'storyth': ['doc2'],\n",
              " 'tale': ['doc2'],\n",
              " 'teach': ['doc2'],\n",
              " 'that': ['doc2', 'doc3', 'doc8', 'doc9', 'doc10'],\n",
              " 'these': ['doc2', 'doc8', 'doc6'],\n",
              " 'they': ['doc2', 'doc8', 'doc10', 'doc6'],\n",
              " 'thi': ['doc2', 'doc8', 'doc10', 'doc6'],\n",
              " 'told': ['doc2', 'doc8', 'doc10'],\n",
              " 'underli': ['doc2'],\n",
              " 'vivid': ['doc2'],\n",
              " 'we': ['doc2', 'doc8', 'doc10'],\n",
              " 'abl': ['doc3'],\n",
              " 'accept': ['doc3'],\n",
              " 'achehumili': ['doc3'],\n",
              " 'ani': ['doc3'],\n",
              " 'arriv': ['doc3', 'doc10'],\n",
              " 'asham': ['doc3'],\n",
              " 'befor': ['doc3', 'doc8'],\n",
              " 'befriend': ['doc3'],\n",
              " 'better': ['doc3', 'doc8'],\n",
              " 'big': ['doc3', 'doc8', 'doc10'],\n",
              " 'bill': ['doc3'],\n",
              " 'both': ['doc3', 'doc8', 'doc10'],\n",
              " 'bowlth': ['doc3'],\n",
              " 'brought': ['doc3', 'doc8'],\n",
              " 'came': ['doc3', 'doc4', 'doc8', 'doc10', 'doc6'],\n",
              " 'cannot': ['doc3'],\n",
              " 'cant': ['doc3', 'doc8'],\n",
              " 'cun': ['doc3'],\n",
              " 'dear': ['doc3', 'doc8'],\n",
              " 'dinnerth': ['doc3'],\n",
              " 'disappoint': ['doc3'],\n",
              " 'dont': ['doc3', 'doc8'],\n",
              " 'easili': ['doc3'],\n",
              " 'enjoy': ['doc3'],\n",
              " 'exchang': ['doc3'],\n",
              " 'feast': ['doc3'],\n",
              " 'felt': ['doc3', 'doc8'],\n",
              " 'finish': ['doc3', 'doc8'],\n",
              " 'foxth': ['doc3'],\n",
              " 'friend': ['doc3', 'doc6'],\n",
              " 'from': ['doc3', 'doc8', 'doc9', 'doc10'],\n",
              " 'gain': ['doc3'],\n",
              " 'given': ['doc3'],\n",
              " 'good': ['doc3', 'doc8'],\n",
              " 'happili': ['doc3', 'doc4'],\n",
              " 'have': ['doc3', 'doc8', 'doc10', 'doc5'],\n",
              " 'health': ['doc3'],\n",
              " 'her': ['doc3', 'doc8', 'doc5', 'doc6'],\n",
              " 'himself': ['doc3', 'doc8'],\n",
              " 'hous': ['doc3', 'doc8'],\n",
              " 'hungri': ['doc3', 'doc8', 'doc10'],\n",
              " 'if': ['doc3', 'doc8'],\n",
              " 'iid': ['doc3'],\n",
              " 'invit': ['doc3'],\n",
              " 'invitationth': ['doc3'],\n",
              " 'jar': ['doc3'],\n",
              " 'just': ['doc3', 'doc8', 'doc10'],\n",
              " 'kitchen': ['doc3', 'doc8'],\n",
              " 'leav': ['doc3', 'doc10'],\n",
              " 'left': ['doc3', 'doc10'],\n",
              " 'lick': ['doc3'],\n",
              " 'live': ['doc3', 'doc8', 'doc10', 'doc6'],\n",
              " 'long': ['doc3', 'doc8', 'doc9', 'doc6'],\n",
              " 'met': ['doc3', 'doc8', 'doc10'],\n",
              " 'mischiev': ['doc3'],\n",
              " 'more': ['doc3', 'doc8', 'doc9', 'doc10'],\n",
              " 'my': ['doc3', 'doc8', 'doc10'],\n",
              " 'narrow': ['doc3'],\n",
              " 'neck': ['doc3'],\n",
              " 'notaft': ['doc3'],\n",
              " 'obvious': ['doc3'],\n",
              " 'offer': ['doc3'],\n",
              " 'offersh': ['doc3'],\n",
              " 'oh': ['doc3', 'doc10'],\n",
              " 'onc': ['doc3', 'doc7', 'doc8', 'doc9', 'doc10', 'doc5'],\n",
              " 'plate': ['doc3'],\n",
              " 'play': ['doc3'],\n",
              " 'pleas': ['doc3', 'doc8', 'doc10'],\n",
              " 'pleasantri': ['doc3'],\n",
              " 'poor': ['doc3', 'doc8'],\n",
              " 'problem': ['doc3'],\n",
              " 'promis': ['doc3'],\n",
              " 'reach': ['doc3', 'doc4', 'doc8'],\n",
              " 'rememb': ['doc3'],\n",
              " 'said': ['doc3', 'doc8', 'doc9', 'doc10'],\n",
              " 'saw': ['doc3', 'doc8', 'doc10'],\n",
              " 'say': ['doc3', 'doc8'],\n",
              " 'shallow': ['doc3'],\n",
              " 'she': ['doc3', 'doc8', 'doc5'],\n",
              " 'some': ['doc3', 'doc4', 'doc8'],\n",
              " 'sorri': ['doc3', 'doc8'],\n",
              " 'soup': ['doc3'],\n",
              " 'soupim': ['doc3'],\n",
              " 'speak': ['doc3', 'doc8'],\n",
              " 'stammer': ['doc3'],\n",
              " 'stomach': ['doc3'],\n",
              " 'stork': ['doc3'],\n",
              " 'surpris': ['doc3'],\n",
              " 'sweetli': ['doc3'],\n",
              " 'thank': ['doc3'],\n",
              " 'their': ['doc3', 'doc10'],\n",
              " 'them': ['doc3', 'doc4', 'doc8', 'doc10', 'doc6'],\n",
              " 'themon': ['doc3'],\n",
              " 'tip': ['doc3'],\n",
              " 'touch': ['doc3'],\n",
              " 'trick': ['doc3', 'doc6'],\n",
              " 'troubl': ['doc3'],\n",
              " 'trust': ['doc3', 'doc8'],\n",
              " 'tummi': ['doc3'],\n",
              " 'upon': ['doc3', 'doc7', 'doc8', 'doc10', 'doc6'],\n",
              " 'upset': ['doc3'],\n",
              " 'use': ['doc3'],\n",
              " 'went': ['doc3', 'doc8', 'doc10'],\n",
              " 'what': ['doc3', 'doc8', 'doc5'],\n",
              " 'away': ['doc4', 'doc8', 'doc10'],\n",
              " 'beak': ['doc4'],\n",
              " 'began': ['doc4', 'doc8'],\n",
              " 'bit': ['doc4', 'doc8'],\n",
              " 'bottom': ['doc4'],\n",
              " 'brilliant': ['doc4', 'doc10'],\n",
              " 'by': ['doc4', 'doc8', 'doc9', 'doc10', 'doc5', 'doc6'],\n",
              " 'clever': ['doc4'],\n",
              " 'couldnt': ['doc4', 'doc8'],\n",
              " 'crow': ['doc4'],\n",
              " 'crowth': ['doc4'],\n",
              " 'delight': ['doc4'],\n",
              " 'drank': ['doc4'],\n",
              " 'drink': ['doc4', 'doc8'],\n",
              " 'drop': ['doc4', 'doc8', 'doc5'],\n",
              " 'final': ['doc4', 'doc10'],\n",
              " 'flew': ['doc4'],\n",
              " 'found': ['doc4', 'doc7', 'doc8', 'doc6'],\n",
              " 'hot': ['doc4'],\n",
              " 'insid': ['doc4', 'doc10'],\n",
              " 'into': ['doc4', 'doc8', 'doc10'],\n",
              " 'look': ['doc4', 'doc8', 'doc9', 'doc10'],\n",
              " 'onli': ['doc4', 'doc8', 'doc9'],\n",
              " 'pebbl': ['doc4'],\n",
              " 'pick': ['doc4'],\n",
              " 'pot': ['doc4', 'doc8'],\n",
              " 'put': ['doc4', 'doc8'],\n",
              " 'rise': ['doc4'],\n",
              " 'search': ['doc4', 'doc8', 'doc10'],\n",
              " 'thirsti': ['doc4'],\n",
              " 'thought': ['doc4', 'doc10', 'doc5'],\n",
              " 'water': ['doc4', 'doc8', 'doc9', 'doc10'],\n",
              " 'whileand': ['doc4'],\n",
              " 'anymor': ['doc7'],\n",
              " 'awayjosh': ['doc7'],\n",
              " 'becaus': ['doc7', 'doc10'],\n",
              " 'call': ['doc7', 'doc8'],\n",
              " 'cave': ['doc7', 'doc10'],\n",
              " 'chase': ['doc7', 'doc10'],\n",
              " 'didnt': ['doc7', 'doc8'],\n",
              " 'eat': ['doc7', 'doc8', 'doc10', 'doc6'],\n",
              " 'fast': ['doc7', 'doc8'],\n",
              " 'find': ['doc7', 'doc6'],\n",
              " 'got': ['doc7', 'doc8', 'doc6'],\n",
              " 'heard': ['doc7', 'doc8'],\n",
              " 'hide': ['doc7'],\n",
              " 'hunt': ['doc7', 'doc10'],\n",
              " 'hunter': ['doc7'],\n",
              " 'josh': ['doc7'],\n",
              " 'joshon': ['doc7'],\n",
              " 'jungl': ['doc7', 'doc6'],\n",
              " 'junglejosh': ['doc7'],\n",
              " 'leo': ['doc7'],\n",
              " 'lostleo': ['doc7'],\n",
              " 'nice': ['doc7'],\n",
              " 'see': ['doc7', 'doc8'],\n",
              " 'spot': ['doc7'],\n",
              " 'through': ['doc7', 'doc8'],\n",
              " 'way': ['doc7', 'doc9', 'doc10', 'doc6'],\n",
              " 'while': ['doc7'],\n",
              " 'afterjack': ['doc8'],\n",
              " 'again': ['doc8', 'doc9'],\n",
              " 'againjack': ['doc8'],\n",
              " 'aliv': ['doc8'],\n",
              " 'allth': ['doc8'],\n",
              " 'along': ['doc8', 'doc9'],\n",
              " 'alway': ['doc8', 'doc6'],\n",
              " 'anoth': ['doc8', 'doc10'],\n",
              " 'are': ['doc8', 'doc9', 'doc10'],\n",
              " 'arent': ['doc8'],\n",
              " 'arm': ['doc8'],\n",
              " 'asleep': ['doc8'],\n",
              " 'astand': ['doc8'],\n",
              " 'ate': ['doc8'],\n",
              " 'attic': ['doc8'],\n",
              " 'axe': ['doc8'],\n",
              " 'back': ['doc8', 'doc10'],\n",
              " 'backright': ['doc8'],\n",
              " 'bad': ['doc8', 'doc10'],\n",
              " 'bag': ['doc8'],\n",
              " 'bean': ['doc8'],\n",
              " 'beansback': ['doc8'],\n",
              " 'beansgo': ['doc8'],\n",
              " 'beanstalk': ['doc8'],\n",
              " 'beauti': ['doc8', 'doc9'],\n",
              " 'becam': ['doc8'],\n",
              " 'bed': ['doc8'],\n",
              " 'been': ['doc8'],\n",
              " 'begun': ['doc8'],\n",
              " 'behind': ['doc8', 'doc6'],\n",
              " 'belt': ['doc8'],\n",
              " 'blood': ['doc8', 'doc5'],\n",
              " 'boil': ['doc8'],\n",
              " 'bold': ['doc8'],\n",
              " 'bone': ['doc8'],\n",
              " 'boy': ['doc8'],\n",
              " 'brass': ['doc8'],\n",
              " 'bread': ['doc8'],\n",
              " 'breadnonsens': ['doc8'],\n",
              " 'breakfast': ['doc8'],\n",
              " 'breakfastl': ['doc8'],\n",
              " 'broad': ['doc8'],\n",
              " 'broke': ['doc8'],\n",
              " 'bundl': ['doc8'],\n",
              " 'bush': ['doc8', 'doc6'],\n",
              " 'cackl': ['doc8'],\n",
              " 'calv': ['doc8'],\n",
              " 'carri': ['doc8'],\n",
              " 'caught': ['doc8'],\n",
              " 'chap': ['doc8'],\n",
              " 'chees': ['doc8'],\n",
              " 'chest': ['doc8'],\n",
              " 'chop': ['doc8'],\n",
              " 'climb': ['doc8', 'doc10'],\n",
              " 'close': ['doc8'],\n",
              " 'cloudsjack': ['doc8'],\n",
              " 'come': ['doc8'],\n",
              " 'cominggood': ['doc8'],\n",
              " 'comingoh': ['doc8'],\n",
              " 'commenc': ['doc8'],\n",
              " 'copper': ['doc8'],\n",
              " 'count': ['doc8'],\n",
              " 'coupl': ['doc8'],\n",
              " 'cow': ['doc8', 'doc6'],\n",
              " 'crawl': ['doc8'],\n",
              " 'crept': ['doc8'],\n",
              " 'cri': ['doc8'],\n",
              " 'crown': ['doc8'],\n",
              " 'cupboard': ['doc8'],\n",
              " 'curiou': ['doc8'],\n",
              " 'cut': ['doc8'],\n",
              " 'dare': ['doc8'],\n",
              " 'dark': ['doc8'],\n",
              " 'dart': ['doc8'],\n",
              " 'dash': ['doc8'],\n",
              " 'deadil': ['doc8'],\n",
              " 'deari': ['doc8'],\n",
              " 'die': ['doc8'],\n",
              " 'dinner': ['doc8'],\n",
              " 'disappear': ['doc8'],\n",
              " 'dodg': ['doc8'],\n",
              " 'doesnt': ['doc8'],\n",
              " 'dolt': ['doc8'],\n",
              " 'done': ['doc8'],\n",
              " 'door': ['doc8'],\n",
              " 'doorstep': ['doc8'],\n",
              " 'doorstepgood': ['doc8'],\n",
              " 'doso': ['doc8'],\n",
              " 'doze': ['doc8'],\n",
              " 'dream': ['doc8'],\n",
              " 'each': ['doc8', 'doc6'],\n",
              " 'earli': ['doc8'],\n",
              " 'earth': ['doc8'],\n",
              " 'eatgo': ['doc8'],\n",
              " 'eatwel': ['doc8'],\n",
              " 'egg': ['doc8'],\n",
              " 'els': ['doc8'],\n",
              " 'end': ['doc8'],\n",
              " 'englishman': ['doc8'],\n",
              " 'englishmanb': ['doc8'],\n",
              " 'enough': ['doc8', 'doc10'],\n",
              " 'everi': ['doc8', 'doc10'],\n",
              " 'everyth': ['doc8'],\n",
              " 'excit': ['doc8'],\n",
              " 'exclaim': ['doc8'],\n",
              " 'feefifofum': ['doc8'],\n",
              " 'fell': ['doc8', 'doc5'],\n",
              " 'fifteen': ['doc8'],\n",
              " 'fine': ['doc8'],\n",
              " 'fire': ['doc8'],\n",
              " 'five': ['doc8', 'doc10'],\n",
              " 'fivetwo': ['doc8'],\n",
              " 'fool': ['doc8', 'doc9'],\n",
              " 'foolah': ['doc8'],\n",
              " 'footstep': ['doc8'],\n",
              " 'fright': ['doc8'],\n",
              " 'funni': ['doc8'],\n",
              " 'garden': ['doc8'],\n",
              " 'gave': ['doc8'],\n",
              " 'giant': ['doc8'],\n",
              " 'give': ['doc8', 'doc10', 'doc5'],\n",
              " 'goe': ['doc8'],\n",
              " 'gold': ['doc8'],\n",
              " 'golden': ['doc8'],\n",
              " 'goldthat': ['doc8'],\n",
              " 'gone': ['doc8'],\n",
              " 'gotten': ['doc8'],\n",
              " 'graciou': ['doc8'],\n",
              " 'great': ['doc8', 'doc10'],\n",
              " 'grew': ['doc8'],\n",
              " 'grind': ['doc8'],\n",
              " 'grow': ['doc8'],\n",
              " 'guess': ['doc8'],\n",
              " 'ha': ['doc8'],\n",
              " 'hadnt': ['doc8'],\n",
              " 'half': ['doc8'],\n",
              " 'hand': ['doc8'],\n",
              " 'handscheer': ['doc8'],\n",
              " 'happen': ['doc8'],\n",
              " 'happi': ['doc8'],\n",
              " 'harp': ['doc8'],\n",
              " 'harpjack': ['doc8'],\n",
              " 'head': ['doc8'],\n",
              " 'hed': ['doc8'],\n",
              " 'heel': ['doc8'],\n",
              " 'hell': ['doc8'],\n",
              " 'hen': ['doc8'],\n",
              " 'henth': ['doc8'],\n",
              " 'hid': ['doc8', 'doc6'],\n",
              " 'himdo': ['doc8'],\n",
              " 'hold': ['doc8'],\n",
              " 'home': ['doc8'],\n",
              " 'hungerwel': ['doc8'],\n",
              " 'hunk': ['doc8'],\n",
              " 'hunterit': ['doc8'],\n",
              " 'idiot': ['doc8'],\n",
              " 'im': ['doc8'],\n",
              " 'ive': ['doc8'],\n",
              " 'jack': ['doc8'],\n",
              " 'jackgood': ['doc8'],\n",
              " 'jackwev': ['doc8'],\n",
              " 'jug': ['doc8'],\n",
              " 'jump': ['doc8', 'doc9', 'doc10'],\n",
              " 'knee': ['doc8'],\n",
              " 'knew': ['doc8', 'doc10'],\n",
              " 'ladder': ['doc8'],\n",
              " 'laid': ['doc8'],\n",
              " 'larder': ['doc8'],\n",
              " 'laywel': ['doc8'],\n",
              " 'leg': ['doc8'],\n",
              " 'lid': ['doc8'],\n",
              " 'life': ['doc8'],\n",
              " 'lift': ['doc8'],\n",
              " 'loudli': ['doc8'],\n",
              " 'luck': ['doc8'],\n",
              " 'luckili': ['doc8'],\n",
              " 'maam': ['doc8'],\n",
              " 'made': ['doc8'],\n",
              " 'magic': ['doc8'],\n",
              " 'man': ['doc8'],\n",
              " 'mani': ['doc8', 'doc10'],\n",
              " 'manim': ['doc8'],\n",
              " 'market': ['doc8'],\n",
              " 'marri': ['doc8'],\n",
              " 'master': ['doc8'],\n",
              " 'matter': ['doc8'],\n",
              " 'may': ['doc8'],\n",
              " 'me': ['doc8', 'doc10'],\n",
              " 'milk': ['doc8'],\n",
              " 'milkwhat': ['doc8'],\n",
              " 'milkywhit': ['doc8'],\n",
              " 'milkywhitehi': ['doc8'],\n",
              " 'mind': ['doc8'],\n",
              " 'miss': ['doc8', 'doc9'],\n",
              " 'money': ['doc8'],\n",
              " 'morn': ['doc8'],\n",
              " 'most': ['doc8'],\n",
              " 'mother': ['doc8'],\n",
              " 'mouth': ['doc8', 'doc9'],\n",
              " 'move': ['doc8'],\n",
              " 'mum': ['doc8'],\n",
              " 'munch': ['doc8'],\n",
              " 'must': ['doc8'],\n",
              " 'mutter': ['doc8'],\n",
              " 'name': ['doc8'],\n",
              " 'namewel': ['doc8'],\n",
              " 'nearli': ['doc8'],\n",
              " 'needleright': ['doc8'],\n",
              " 'never': ['doc8', 'doc6'],\n",
              " 'nightso': ['doc8'],\n",
              " 'no': ['doc8', 'doc10', 'doc5'],\n",
              " 'nobodi': ['doc8'],\n",
              " 'nod': ['doc8'],\n",
              " 'nois': ['doc8'],\n",
              " 'noth': ['doc8'],\n",
              " 'number': ['doc8', 'doc10'],\n",
              " 'off': ['doc8', 'doc9'],\n",
              " 'ogr': ['doc8'],\n",
              " 'old': ['doc8'],\n",
              " 'onto': ['doc8'],\n",
              " 'open': ['doc8'],\n",
              " 'or': ['doc8', 'doc10'],\n",
              " 'our': ['doc8', 'doc10'],\n",
              " 'oven': ['doc8'],\n",
              " 'ovenal': ['doc8'],\n",
              " 'ovenjack': ['doc8'],\n",
              " 'over': ['doc8'],\n",
              " 'overnight': ['doc8'],\n",
              " 'oxenthen': ['doc8'],\n",
              " 'pail': ['doc8'],\n",
              " 'part': ['doc8'],\n",
              " 'past': ['doc8'],\n",
              " 'pelter': ['doc8'],\n",
              " 'perhap': ['doc8'],\n",
              " 'plant': ['doc8'],\n",
              " 'pocket': ['doc8'],\n",
              " 'polit': ['doc8'],\n",
              " 'potaft': ['doc8'],\n",
              " 'pound': ['doc8'],\n",
              " 'preciou': ['doc8'],\n",
              " 'princess': ['doc8'],\n",
              " 'proper': ['doc8'],\n",
              " 'pull': ['doc8'],\n",
              " 'quick': ['doc8'],\n",
              " 'quietli': ['doc8'],\n",
              " 'quit': ['doc8', 'doc10'],\n",
              " 'quiver': ['doc8'],\n",
              " 'readi': ['doc8', 'doc9'],\n",
              " 'realli': ['doc8'],\n",
              " 'rest': ['doc8'],\n",
              " 'rich': ['doc8'],\n",
              " 'right': ['doc8', 'doc6'],\n",
              " 'road': ['doc8'],\n",
              " 'robinson': ['doc8'],\n",
              " 'rogu': ['doc8'],\n",
              " 'room': ['doc8'],\n",
              " 'rose': ['doc8'],\n",
              " 'rush': ['doc8'],\n",
              " 'sad': ['doc8'],\n",
              " 'saidfeefifofumi': ['doc8'],\n",
              " 'sang': ['doc8'],\n",
              " 'sat': ['doc8', 'doc9'],\n",
              " 'scarc': ['doc8'],\n",
              " 'scrap': ['doc8'],\n",
              " 'seeso': ['doc8'],\n",
              " 'sell': ['doc8'],\n",
              " 'shadi': ['doc8'],\n",
              " 'shake': ['doc8'],\n",
              " 'shall': ['doc8'],\n",
              " 'sharp': ['doc8'],\n",
              " 'shine': ['doc8'],\n",
              " 'shook': ['doc8'],\n",
              " 'shop': ['doc8'],\n",
              " 'show': ['doc8', 'doc10'],\n",
              " 'sinc': ['doc8', 'doc10'],\n",
              " 'sing': ['doc8'],\n",
              " 'sky': ['doc8'],\n",
              " 'skyreal': ['doc8'],\n",
              " 'sleepwhen': ['doc8'],\n",
              " 'smell': ['doc8'],\n",
              " 'snore': ['doc8'],\n",
              " 'sold': ['doc8'],\n",
              " 'someon': ['doc8'],\n",
              " 'someth': ['doc8'],\n",
              " 'somethingalright': ['doc8'],\n",
              " 'somewher': ['doc8'],\n",
              " 'son': ['doc8'],\n",
              " 'sort': ['doc8'],\n",
              " 'soy': ['doc8'],\n",
              " 'spoke': ['doc8'],\n",
              " 'sprung': ['doc8'],\n",
              " 'startjust': ['doc8'],\n",
              " 'still': ['doc8'],\n",
              " 'stole': ['doc8'],\n",
              " 'stood': ['doc8'],\n",
              " 'stop': ['doc8'],\n",
              " 'straight': ['doc8'],\n",
              " 'strang': ['doc8'],\n",
              " 'strung': ['doc8'],\n",
              " 'stuck': ['doc8'],\n",
              " 'such': ['doc8'],\n",
              " 'suddenli': ['doc8'],\n",
              " 'sun': ['doc8'],\n",
              " 'sup': ['doc8'],\n",
              " 'sure': ['doc8'],\n",
              " 'swallow': ['doc8'],\n",
              " 'swap': ['doc8'],\n",
              " 'sworn': ['doc8'],\n",
              " 'swung': ['doc8'],\n",
              " 'tabl': ['doc8'],\n",
              " 'tall': ['doc8'],\n",
              " 'tell': ['doc8'],\n",
              " 'ten': ['doc8'],\n",
              " 'themselv': ['doc8', 'doc6'],\n",
              " 'then': ['doc8', 'doc10', 'doc5'],\n",
              " 'thereoh': ['doc8'],\n",
              " 'theyr': ['doc8'],\n",
              " 'three': ['doc8', 'doc5'],\n",
              " 'threw': ['doc8'],\n",
              " 'thrown': ['doc8'],\n",
              " 'thump': ['doc8'],\n",
              " 'thunderthen': ['doc8'],\n",
              " 'tidi': ['doc8'],\n",
              " 'till': ['doc8', 'doc10'],\n",
              " 'tipto': ['doc8'],\n",
              " 'toast': ['doc8'],\n",
              " 'today': ['doc8'],\n",
              " 'took': ['doc8', 'doc9', 'doc10'],\n",
              " 'top': ['doc8'],\n",
              " 'toppl': ['doc8'],\n",
              " 'topthi': ['doc8'],\n",
              " 'toward': ['doc8'],\n",
              " 'trembl': ['doc8'],\n",
              " 'true': ['doc8'],\n",
              " 'truli': ['doc8'],\n",
              " 'truth': ['doc8'],\n",
              " 'turn': ['doc8', 'doc10'],\n",
              " 'twenti': ['doc8'],\n",
              " 'twentyi': ['doc8'],\n",
              " 'two': ['doc8'],\n",
              " 'under': ['doc8'],\n",
              " 'underneath': ['doc8'],\n",
              " 'unhook': ['doc8'],\n",
              " 'upstair': ['doc8'],\n",
              " 'wait': ['doc8', 'doc10', 'doc6'],\n",
              " 'walk': ['doc8', 'doc9', 'doc10'],\n",
              " 'want': ['doc8', 'doc10'],\n",
              " 'wash': ['doc8'],\n",
              " 'wasnt': ['doc8'],\n",
              " 'weight': ['doc8'],\n",
              " 'well': ['doc8', 'doc10'],\n",
              " 'whi': ['doc8', 'doc10'],\n",
              " 'which': ['doc8', 'doc10'],\n",
              " 'whole': ['doc8'],\n",
              " 'widow': ['doc8'],\n",
              " 'wife': ['doc8'],\n",
              " 'wifefeefifofum': ['doc8'],\n",
              " 'will': ['doc8', 'doc10'],\n",
              " 'window': ['doc8', 'doc5'],\n",
              " 'woke': ['doc8'],\n",
              " 'woman': ['doc8'],\n",
              " 'womangood': ['doc8'],\n",
              " 'wonder': ['doc8'],\n",
              " 'work': ['doc8'],\n",
              " 'would': ['doc8', 'doc10', 'doc5'],\n",
              " 'wring': ['doc8'],\n",
              " 'yard': ['doc8'],\n",
              " 'yesterday': ['doc8'],\n",
              " 'yet': ['doc8'],\n",
              " 'youd': ['doc8'],\n",
              " 'youll': ['doc8'],\n",
              " 'youngster': ['doc8'],\n",
              " 'your': ['doc8', 'doc10'],\n",
              " 'youso': ['doc8'],\n",
              " 'am': ['doc9'],\n",
              " 'branch': ['doc9'],\n",
              " 'bunch': ['doc9'],\n",
              " 'burst': ['doc9'],\n",
              " 'disgustwhat': ['doc9'],\n",
              " 'fall': ['doc9'],\n",
              " 'first': ['doc9'],\n",
              " 'forand': ['doc9'],\n",
              " 'gape': ['doc9'],\n",
              " 'gaze': ['doc9'],\n",
              " 'grape': ['doc9'],\n",
              " 'hang': ['doc9'],\n",
              " 'high': ['doc9'],\n",
              " 'hung': ['doc9'],\n",
              " 'juic': ['doc9'],\n",
              " 'leap': ['doc9'],\n",
              " 'longingli': ['doc9'],\n",
              " 'myself': ['doc9'],\n",
              " 'ripe': ['doc9'],\n",
              " 'scorn': ['doc9'],\n",
              " 'seem': ['doc9'],\n",
              " 'sour': ['doc9'],\n",
              " 'spi': ['doc9'],\n",
              " 'themth': ['doc9'],\n",
              " 'train': ['doc9'],\n",
              " 'tree': ['doc9'],\n",
              " 'vainnow': ['doc9'],\n",
              " 'vine': ['doc9'],\n",
              " 'wear': ['doc9'],\n",
              " 'worth': ['doc9'],\n",
              " 'afternoon': ['doc10', 'doc5'],\n",
              " 'alon': ['doc10'],\n",
              " 'alreadi': ['doc10'],\n",
              " 'also': ['doc10'],\n",
              " 'angri': ['doc10'],\n",
              " 'appear': ['doc10'],\n",
              " 'arrang': ['doc10'],\n",
              " 'beat': ['doc10'],\n",
              " 'calm': ['doc10'],\n",
              " 'considerationth': ['doc10'],\n",
              " 'conveni': ['doc10'],\n",
              " 'deep': ['doc10'],\n",
              " 'den': ['doc10'],\n",
              " 'determin': ['doc10'],\n",
              " 'devis': ['doc10'],\n",
              " 'devour': ['doc10'],\n",
              " 'downh': ['doc10'],\n",
              " 'dwindl': ['doc10'],\n",
              " 'echo': ['doc10'],\n",
              " 'edg': ['doc10'],\n",
              " 'enrag': ['doc10'],\n",
              " 'even': ['doc10', 'doc6'],\n",
              " 'everybodi': ['doc10'],\n",
              " 'expect': ['doc10'],\n",
              " 'extinct': ['doc10'],\n",
              " 'extrem': ['doc10'],\n",
              " 'famish': ['doc10'],\n",
              " 'feroci': ['doc10'],\n",
              " 'fill': ['doc10'],\n",
              " 'flash': ['doc10'],\n",
              " 'foodth': ['doc10'],\n",
              " 'foolish': ['doc10'],\n",
              " 'forest': ['doc10'],\n",
              " 'furiou': ['doc10'],\n",
              " 'game': ['doc10'],\n",
              " 'gobbl': ['doc10'],\n",
              " 'hear': ['doc10'],\n",
              " 'helpless': ['doc10'],\n",
              " 'huge': ['doc10'],\n",
              " 'hungerh': ['doc10'],\n",
              " 'impati': ['doc10'],\n",
              " 'indeedth': ['doc10'],\n",
              " 'inform': ['doc10'],\n",
              " 'infuri': ['doc10'],\n",
              " 'instanta': ['doc10'],\n",
              " 'intellig': ['doc10'],\n",
              " 'kill': ['doc10', 'doc6'],\n",
              " 'king': ['doc10'],\n",
              " 'lack': ['doc10'],\n",
              " 'larg': ['doc10'],\n",
              " 'late': ['doc10'],\n",
              " 'lead': ['doc10'],\n",
              " 'let': ['doc10'],\n",
              " 'listen': ['doc10'],\n",
              " 'longer': ['doc10'],\n",
              " 'majesti': ['doc10'],\n",
              " 'meal': ['doc10', 'doc6'],\n",
              " 'mean': ['doc10'],\n",
              " 'mighti': ['doc10'],\n",
              " 'new': ['doc10'],\n",
              " 'overpow': ['doc10'],\n",
              " 'own': ['doc10', 'doc6'],\n",
              " 'pace': ['doc10'],\n",
              " 'plan': ['doc10', 'doc6'],\n",
              " 'plea': ['doc10'],\n",
              " 'point': ['doc10'],\n",
              " 'power': ['doc10'],\n",
              " 'puni': ['doc10'],\n",
              " 'quickest': ['doc10'],\n",
              " 'rabbit': ['doc10'],\n",
              " 'rate': ['doc10'],\n",
              " 'raven': ['doc10'],\n",
              " 'reflect': ['doc10'],\n",
              " 'request': ['doc10'],\n",
              " 'result': ['doc10'],\n",
              " 'return': ['doc10'],\n",
              " 'roar': ['doc10'],\n",
              " 'saidth': ['doc10'],\n",
              " 'satisfi': ['doc10'],\n",
              " 'send': ['doc10'],\n",
              " 'sent': ['doc10'],\n",
              " 'shock': ['doc10'],\n",
              " 'silli': ['doc10'],\n",
              " 'six': ['doc10'],\n",
              " 'smart': ['doc10'],\n",
              " 'spare': ['doc10'],\n",
              " 'stand': ['doc10'],\n",
              " 'stay': ['doc10'],\n",
              " 'substanti': ['doc10'],\n",
              " 'sunset': ['doc10'],\n",
              " 'swim': ['doc10'],\n",
              " 'terrifi': ['doc10'],\n",
              " 'though': ['doc10'],\n",
              " 'tini': ['doc10'],\n",
              " 'togeth': ['doc10', 'doc6'],\n",
              " 'total': ['doc10'],\n",
              " 'us': ['doc10'],\n",
              " 'ventur': ['doc10'],\n",
              " 'viciou': ['doc10'],\n",
              " 'vow': ['doc10'],\n",
              " 'waterh': ['doc10'],\n",
              " 'were': ['doc10', 'doc6'],\n",
              " 'whenev': ['doc10'],\n",
              " 'without': ['doc10'],\n",
              " 'cheek': ['doc5'],\n",
              " 'daughter': ['doc5'],\n",
              " 'finger': ['doc5'],\n",
              " 'griev': ['doc5'],\n",
              " 'herselfah': ['doc5'],\n",
              " 'prick': ['doc5'],\n",
              " 'queen': ['doc5'],\n",
              " 'red': ['doc5'],\n",
              " 'sew': ['doc5'],\n",
              " 'sit': ['doc5'],\n",
              " 'skin': ['doc5'],\n",
              " 'snow': ['doc5'],\n",
              " 'sore': ['doc5'],\n",
              " 'white': ['doc5'],\n",
              " 'winter': ['doc5'],\n",
              " 'ago': ['doc6'],\n",
              " 'among': ['doc6'],\n",
              " 'attack': ['doc6'],\n",
              " 'closer': ['doc6'],\n",
              " 'danger': ['doc6'],\n",
              " 'eye': ['doc6'],\n",
              " 'fight': ['doc6'],\n",
              " 'four': ['doc6'],\n",
              " 'graze': ['doc6'],\n",
              " 'inde': ['doc6'],\n",
              " 'lone': ['doc6'],\n",
              " 'opportun': ['doc6'],\n",
              " 'pounc': ['doc6'],\n",
              " 'prey': ['doc6'],\n",
              " 'save': ['doc6'],\n",
              " 'separ': ['doc6'],\n",
              " 'tiger': ['doc6'],\n",
              " 'uniti': ['doc6']}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}